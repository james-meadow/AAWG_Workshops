{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXnMKONwagOU"
   },
   "source": [
    "# Python for Data Science \n",
    "\n",
    "#### AAWG Dev Day 6/14/2019 \n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "# Python for Data Science \n",
    "\n",
    "#### AAWG Dev Day 6/14/2019 \n",
    "\n",
    "------------\n",
    "\n",
    "### Python \n",
    "\n",
    "Is an interesting and fun language. It is rapidly taking over the for both engineering and data science. It can be extremely powerful, and powers some of the everyday products you use. But it can also be painfully slow and clunky if you use it incorrectly. Here are a few important considerations to keep in mind: \n",
    "\n",
    "#### History \n",
    "\n",
    "* Conceived in 1980 \n",
    "* Python 2.0 released in 2000, which is also about the time it became a popular, powerful language \n",
    "* 3.0 released 2008. Unless you have a very good reason, **always begin a project in python 3 instead of python 2!** \n",
    "* The name and lots of instructional/infrastructural concepts are borrowed from Monty Python \n",
    "\n",
    "#### Programming paradigms \n",
    "\n",
    "Python supports procedural, object-oriented, functional programming. \n",
    "\n",
    "Everything we do today (and most data science workloads) are *functional* programming. Most engineering projects require *object-oriented* programming. \n",
    "\n",
    "#### Opinionated \n",
    "\n",
    "Python has some quirks, but in general is a very friendly language. Here are a few important things to keep in mind: \n",
    "\n",
    "* Whitespace is extremely important \n",
    "  * Indentation is a part of the language and cannot be ignored. Must be consistent throughout. Tabs vs spaces, # of spaces, etc. \n",
    "* Documentation is often very difficult to understand when you get started, so you'll rely on StackOverflow etc for most problems and examples. Don't let SO super-users get to you. They are often not nice. \n",
    "* Jupyter is a nice place to play and experiment. Production code generally lives in a package of scripts (modules) \n",
    "* Unlike compiled languages, python will let you execute a script that won't work. You'll catch errors as the interpreter finds them. Thus **work in small chunks and test often!!** \n",
    "* If you indent more than 2 levels, rethink (no more than 2 nested if statements, for example) \n",
    "* Each function should do something specific and do it in a clean way. Resist the urge to pack everything into a single function \n",
    "\n",
    "\n",
    "\n",
    "#### Philosophy \n",
    "\n",
    "* Beautiful is better than ugly\n",
    "* Explicit is better than implicit\n",
    "* Simple is better than complex\n",
    "* Complex is better than complicated\n",
    "* Readability counts\n",
    "\n",
    "Try the `import this` command below :) \n",
    "\n",
    "#### Comments \n",
    "\n",
    "    # this is invisible to python. \n",
    "    # Use this for short comments \n",
    "    # It is ok for each line to have a comment! \n",
    "    print('but this will be evaluated') \n",
    "    \n",
    "    \"\"\"\n",
    "    This is a block comment. \n",
    "    Use these to be verbose about \n",
    "    your function or block of code. \n",
    "    You are writing comments so that \n",
    "    your future self won't be embarassed! \n",
    "    All functions need to begin with a block comment! \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#### Additional Resources \n",
    "\n",
    "Some examples in this exercise were taken from 2 excellent books: \n",
    "\n",
    "* [Machine Learning with Python Cookbook.](https://www.amazon.com/Machine-Learning-Python-Cookbook-Preprocessing/dp/1491989386/ref=asc_df_1491989386/?tag=hyprod-20&linkCode=df0&hvadid=312114711253&hvpos=1o2&hvnetw=g&hvrand=6564831004064313021&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9031977&hvtargid=pla-440699598191&psc=1) Chris Albon. \n",
    "* [Data Science from Scratch](https://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/1492041130/ref=asc_df_1492041130/?tag=hyprod-20&linkCode=df0&hvadid=343276535408&hvpos=1o1&hvnetw=g&hvrand=12496244881379603440&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9031977&hvtargid=pla-699588372177&psc=1&tag=&ref=&adgrpid=74543737372&hvpone=&hvptwo=&hvadid=343276535408&hvpos=1o1&hvnetw=g&hvrand=12496244881379603440&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9031977&hvtargid=pla-699588372177). Joel Grus. \n",
    "\n",
    "These are great resources from all levels of python data scientists. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data types. \n",
    "\n",
    "### Lists \n",
    "\n",
    "Lists are the most simple collection of data objects. You can mix and match within a list, but this will create problems sometimes. Generally you should keep a single list to the same type (number vs text). \n",
    "\n",
    "You can start a new empy list like this, and then use the `append` function to add items to the list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oxhcWLqdbMZV",
    "outputId": "563f519f-7be5-4bb0-8fd2-20db891ac795"
   },
   "outputs": [],
   "source": [
    "l = [] \n",
    "l.append('item 1')\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArEmkIA2bjL4"
   },
   "source": [
    "Or you can initiate a list with data already in it. Here are several lists we'll reuse below. Note there are mixed data types. \n",
    "\n",
    "**See if you can deduce what assumptions/choices python is making when we do this.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f01ev3EmhO3Y"
   },
   "outputs": [],
   "source": [
    "first_name = ['Jason', 'Molly', 'Tina', 'Jake', 'Amy']\n",
    "last_name = ['Miller', 'Jacobson', \".\", 'Milner', 'Cooze'] \n",
    "age = [42, 52, 36, 24, 73] \n",
    "preTestScore = [4, 24, 31, \".\", \".\"]\n",
    "postTestScore = [\"25,000\", \"94,000\", 57, 62, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jM4DVlYB0bMW"
   },
   "outputs": [],
   "source": [
    "# type(preTestScore[1])\n",
    "type(preTestScore[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTUIAjOnzHiC"
   },
   "source": [
    "Now that we have lists, we need to learn to extract information from them. We can do this with simple indexing, which in python begins with 0 (not 1). \n",
    "\n",
    "**What is the `[-1]` index doing?** \n",
    "\n",
    "**Print the list in reverse order?**  \n",
    " \n",
    "**Print all but the first** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGs2XoSwzVjG"
   },
   "outputs": [],
   "source": [
    "first_name[0]\n",
    "# first_name[0:1]\n",
    "# first_name[2:]\n",
    "# first_name[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hw72yR3w0T9z"
   },
   "outputs": [],
   "source": [
    "first_name[::-1]\n",
    "# first_name[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4XJ7wtFcqsF"
   },
   "source": [
    "### DataFrames\n",
    "\n",
    "For data science jobs, lists are usually a starting place, but sometimes not useful by themselves. So next we can put them into a `pandas` **DataFrame** object. **This is the canonical data science format, so knowing DF is crucial!** \n",
    "\n",
    "First, we need the `pandas` library. This will essentially always be used for data science jobs in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3NDTNz51HQ_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJKZOgqG1RkS"
   },
   "source": [
    "There are multiple ways to get lists into a DF. Here is an example of using the `zip` function to *zipper* together multiple lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "pzldlKBvkjqG",
    "outputId": "28808adc-3a49-474f-a93e-67a2669cbbc2"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(first_name, last_name, age)), \n",
    "                  columns=['first_name', 'last_name', 'age'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkWiwnYlqKaE"
   },
   "source": [
    "**Create a 1-column DataFrame out of a single list.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWVCiPTg0YRA"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(first_name, columns=['first_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PqMcrLe_0jSi"
   },
   "source": [
    "### Dictionaries \n",
    "\n",
    "Dictionaries are the second essential data structure you'll need for data science in python. These are kind of like lists, but are based on a `{key: data}` structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sW9oyhr307ok"
   },
   "outputs": [],
   "source": [
    "d = {'key': [1, 2, 3]}\n",
    "d['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__2Ciekw1Qni"
   },
   "source": [
    "Notice you can retrieve data using key words, and dictionaries can be much more complex than lists. \n",
    "\n",
    "**See if you can add another key and associated data into the `d` dict we created above.**\n",
    "\n",
    "**Are there any limitations? Does it need to be the same length as the original key+data? How about mixing data types?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "801HbCqe1tlq"
   },
   "outputs": [],
   "source": [
    "d['key1'] = [4, 5, 6, 7, 'fish']\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5z4DP8Ka1ucd"
   },
   "source": [
    "Next, let's reproduce the first/last name DataFrame using a dictionary this time. \n",
    "\n",
    "**What is the `columns` arg doing? What happens if you rearrange the column order.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "B6rM1qtvNpvJ",
    "outputId": "1768a177-fa9d-4fac-d16f-60b48c646b11",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
    "            'last_name': ['Miller', 'Jacobson', \".\", 'Milner', 'Cooze'], \n",
    "            'age': [42, 52, 36, 24, 73], \n",
    "            'preTestScore': [4, 24, 31, \".\", \".\"],\n",
    "            'postTestScore': [\"25,000\", \"94,000\", 57, 62, 70]}\n",
    "df = pd.DataFrame(raw_data, \n",
    "                  columns = ['first_name', \n",
    "                             'last_name', \n",
    "                             'age', \n",
    "                             'preTestScore', \n",
    "                             'postTestScore'], \n",
    "                 index = ['a', 'b', 'c', 'd', 'e'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuOj7Vql2TLs"
   },
   "source": [
    "**Print the first and third columns together**\n",
    "\n",
    "**Print the last name `Milner`** \n",
    "\n",
    "**Now do the same thing with a slightly different command** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['d', 'last_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuples \n",
    "\n",
    "... Are generally not necessary in data science workstreams. But you will occasionally run into them, so best to understand how to deal. If you remember anything from today, don't let it be tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = (1, 4, ['this', 'that', 'the other'])\n",
    "t2 = (2, 5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace 'this' with something else.**\n",
    "\n",
    "**Then replace 4 with something else. ?!?!?** \n",
    "\n",
    "**Just for fun throw a pandas DataFrame into one of your tuples. Why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[2][0] = 'those'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = (1, 2, 3, pd.DataFrame(['another', 'data', 'frame']))\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuples can be turned into lists or dicts, and then you can cycle through them like you would other data structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = [t1, t2]\n",
    "t3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of tuples, we can pull the 2nd element from each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t[1] for t in t3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLKSiYaL21bA"
   },
   "source": [
    "### Changing data in a DataFrame\n",
    "\n",
    "The print commands above don't actually change the DF. Sometimes it is important to replace/remove/add data. \n",
    "\n",
    "Run the commands below, and see what happens. Is this what you expected to happen? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Xf4QRdW21E6"
   },
   "outputs": [],
   "source": [
    "df_trimmed = df.iloc[1:3, :]\n",
    "df_trimmed.loc['c', 'age'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8nemFLphMEh"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok, now see if you can find one of the many ways to change data in just a *copy* of your DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vz9m4pxWUr8m",
    "outputId": "677568f4-cb91-441b-d183-d64fd4dcf163"
   },
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy.loc['c', 'age'] = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOazSIPwfQC_"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! Now that you figured that out, you have a version control problem... \n",
    "So there is a good reason why python developers made that difficult. \n",
    "\n",
    "But you know how to do it when you need to. \n",
    "\n",
    "In reality, you might want to make a habit of creating a raw, untouched copy each time you begin transforming your data. That way it is handy in case you make mistakes. Then you can always come back to the original. But generally avoid making lots of copies of your data!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **lots and lots** of important operations that `numpy` and `pandas` can do. \n",
    "We've just scratched the surface. \n",
    "When you need more, you'll get really comfortable with package documentation and StackOverflow! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with files\n",
    "\n",
    "Reading data into python can be a pain. Luckily `pandas` has nice functions to smooth the process. \n",
    "\n",
    "First, orient within the file system. Note that Colab gives us a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the data frame just to illustrate that it is gone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('test_df.xlsx') #, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('test_df.xlsx') #, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///test_df.db', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute('DROP TABLE IF EXISTS users;')\n",
    "df.to_sql('users', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM users\", engine, index_col='index')\n",
    "\n",
    "# df.index.name = None \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the name of the index is now visible. It is still just an index, but now you can call it by name. \n",
    "\n",
    "**See if you can remove the name `index` from the index column so the table prints out just like it did a few cells above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping\n",
    "\n",
    "Often in python, the fastest and most efficient way to do something with data is to loop through. Not always! But often. All python workloads will have a bit of looping. There are multiple ways to make it happen. \n",
    "\n",
    "First, let's loop through a list the most common way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name = ['Jason', 'Molly', 'Tina', 'Jake', 'Amy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in first_name: \n",
    "    print(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in first_name: print(name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a really powerful complex way to do something simple in a loop. This is known as 'list comprehension'. Get good at it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(name) for name in first_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this creates a little empty list as an artifact. That's because we're using the `[]` list brackets but not putting anything in them. List comprehension is most useful when creating a list by doing something simple to another list or other group of objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_names = ['first name = ' + name for name in first_name]\n",
    "annotated_names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there is not a known finite number of times we need to do something. So instead of traditional looping, we can keep doing a thing until we get the result we want: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_amy = True\n",
    "i = 0\n",
    "while first_name[i] != 'Amy': \n",
    "    print('first name = ' + first_name[i])\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `if` statements\n",
    "\n",
    "You essentially always need some sort of if decision logic during a project there are many ways to do it. Here are some simple examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Jake' in first_name: \n",
    "    print('Found Jake!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'James' not in first_name: \n",
    "    print('James is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'James' in first_name: \n",
    "    print('Found James!')\n",
    "elif 'Jake' in first_name: \n",
    "    print('Found Jake!')\n",
    "else: \n",
    "    print('found nothing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about Data Frames and their Framed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason to get data quickly into `pandas` is so that you can use the fabulous selection of data-manipulation and stats functions on your data. Here are a few simple examples using some datasets already loaded into the data science packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What format is the iris dataset by default?**\n",
    "\n",
    "**Can you turn it into a DataFrame named `df`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris_data.data, columns = iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iris` table is a classic plant physiology dataset that is often used to test ML clustering and classification algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_sepal = df[df['sepal length'] > 7]\n",
    "df_big_sepal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now find all the rows with sepal width ALSO > 3** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sepal = df[(df['sepal width'] > 3) & (df['sepal length'] > 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sepal.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_sepal['petal width'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the average of the second and third columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sepal.iloc[:, 1:3].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing/bad data\n",
    "\n",
    "Almost always an issue. So let's deal with it. First let's create some missing data. \n",
    "\n",
    "numpy has a simple NaN representation that works nicely for our needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "df['petal length'] = df['petal length'].replace(6.1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then remove those entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and summarizing your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "df['group'] = np.random.choice(['r', 'g', 'b'], df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('group').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `apply` functions\n",
    "\n",
    "You can get much more creative about applying functions to entire columns or groups, but you'll need to pass the data through a function like `apply`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('group').apply(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data\n",
    "\n",
    "`matplotlib` will do 90% or more of the plotting you need during routine data science. There are **many, many, many** different things you can do, and it (with other fuctionality) is becoming as good as R for visualization. \n",
    "\n",
    "We'll just look at a super simple example here, with one simple style option envoked. Every variation of plotting in python is accessible with a quick search. \n",
    "\n",
    "Notice also that we're reloading a clean version of the `iris` dataset with its true response category (`species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()\n",
    "iris = pd.DataFrame(iris_data.data, columns = iris_data.feature_names)\n",
    "iris['species'] = iris_data.target\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot(kind='scatter', x='petal width (cm)', y='petal length (cm)', color=iris['species'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the `sepal` variables show the same pattern?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot(kind='scatter', x='sepal width (cm)', y='sepal length (cm)', color=iris['species'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing functions\n",
    "\n",
    "If your workflow is extensive at all, you'll certainly need to write efficient, readable functions that do complex operations. In general, any task that gets coded more than 2x should consider moving to a clean function. \n",
    "\n",
    "For example, let's do something special to some of the items in the dataset. We'll use some logic in a function. \n",
    "\n",
    "When writing functions and loops, pay close attention to your indention!! This matters in python. Mixed tabs and spaces will cause problems, as will any other mismatched indentions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_me(data, length=6): \n",
    "    ## Takes a single element, \n",
    "    ##, and prints the value \n",
    "    ## if it is greater than \n",
    "    ## the threshold `length` arg. \n",
    "    if data > length: \n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in list(df['sepal length']): \n",
    "    show_me(data, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a tiny taste of python's functional programming capability. It goes **way way** deeper than this. And then there is object-oriented programming, which we don't even touch here. \n",
    "\n",
    "Often during a data science process, I end up with a script of small functions that do repeatable things, and then a runner script that calls those functions. Or you can put the function near the top of your notebook, and then call it below. \n",
    "\n",
    "Notice something really important above. The commented description tells you everything you need to know to use the function correctly. It is nota problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AAWG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
